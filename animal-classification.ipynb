{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-15T20:03:29.855628Z",
     "iopub.status.busy": "2024-12-15T20:03:29.855383Z",
     "iopub.status.idle": "2024-12-15T20:03:32.134859Z",
     "shell.execute_reply": "2024-12-15T20:03:32.134235Z",
     "shell.execute_reply.started": "2024-12-15T20:03:29.855591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.utils import class_weight, shuffle\n",
    "\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2024-12-15T20:03:32.136875Z",
     "iopub.status.busy": "2024-12-15T20:03:32.136602Z",
     "iopub.status.idle": "2024-12-15T20:03:35.487939Z",
     "shell.execute_reply": "2024-12-15T20:03:35.487113Z",
     "shell.execute_reply.started": "2024-12-15T20:03:32.136823Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "foldernames = os.listdir('/kaggle/input/animals10/raw-img')\n",
    "categories = []\n",
    "files = []\n",
    "i = 0\n",
    "for k, folder in enumerate(foldernames):\n",
    "    filenames = os.listdir(\"../input/animals10/raw-img/\" + folder);\n",
    "    for file in filenames:\n",
    "        files.append(\"../input/animals10/raw-img/\" + folder + \"/\" + file)\n",
    "        categories.append(k)\n",
    "        \n",
    "df = pd.DataFrame({\n",
    "    'filename': files,\n",
    "    'category': categories\n",
    "})\n",
    "train_df = pd.DataFrame(columns=['filename', 'category'])\n",
    "for i in range(10):\n",
    "    subset_df = df[df.category == i].iloc[:500,:]  # Lấy 500 bản ghi từ mỗi category\n",
    "    train_df = pd.concat([train_df, subset_df], ignore_index=True)  # Kết hợp các DataFrame\n",
    "\n",
    "train_df.head()\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T20:03:35.489491Z",
     "iopub.status.busy": "2024-12-15T20:03:35.489188Z",
     "iopub.status.idle": "2024-12-15T20:03:35.495614Z",
     "shell.execute_reply": "2024-12-15T20:03:35.494961Z",
     "shell.execute_reply.started": "2024-12-15T20:03:35.489437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y = train_df['category']\n",
    "x = train_df['filename']\n",
    "y = train_df['category']\n",
    "\n",
    "x, y = shuffle(x, y, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T20:03:35.497175Z",
     "iopub.status.busy": "2024-12-15T20:03:35.496922Z",
     "iopub.status.idle": "2024-12-15T20:04:20.056640Z",
     "shell.execute_reply": "2024-12-15T20:04:20.055924Z",
     "shell.execute_reply.started": "2024-12-15T20:03:35.497119Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def centering_image(img):\n",
    "    size = [256,256]\n",
    "    \n",
    "    img_size = img.shape[:2]\n",
    "    \n",
    "    # centering\n",
    "    row = (size[1] - img_size[0]) // 2\n",
    "    col = (size[0] - img_size[1]) // 2\n",
    "    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n",
    "    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n",
    "\n",
    "    return resized\n",
    "\n",
    "images = []\n",
    "with tqdm(total=len(train_df)) as pbar:\n",
    "    for i, file_path in enumerate(train_df.filename.values):\n",
    "        #read image\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        #resize\n",
    "        if(img.shape[0] > img.shape[1]):\n",
    "            tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "        else:\n",
    "            tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "\n",
    "        #centering\n",
    "        img = centering_image(cv2.resize(img, dsize=tile_size))\n",
    "\n",
    "        #out put 224*224px \n",
    "        img = img[16:240, 16:240]\n",
    "        images.append(img)\n",
    "        pbar.update(1)\n",
    "\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T20:04:20.059886Z",
     "iopub.status.busy": "2024-12-15T20:04:20.059579Z",
     "iopub.status.idle": "2024-12-15T20:04:21.497512Z",
     "shell.execute_reply": "2024-12-15T20:04:21.496677Z",
     "shell.execute_reply.started": "2024-12-15T20:04:20.059836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "rows,cols = 2,5\n",
    "fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(20,20))\n",
    "for i in range(10):\n",
    "    path = train_df[train_df.category == i].values[2]\n",
    "#     image = cv2.imread(path[0])/\n",
    "    axes[i//cols, i%cols].set_title(path[0].split('/')[-2] + str(path[1]))\n",
    "    axes[i//cols, i%cols].imshow(images[train_df[train_df.filename == path[0]].index[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T20:04:21.499142Z",
     "iopub.status.busy": "2024-12-15T20:04:21.498928Z",
     "iopub.status.idle": "2024-12-15T20:04:24.790257Z",
     "shell.execute_reply": "2024-12-15T20:04:24.789627Z",
     "shell.execute_reply.started": "2024-12-15T20:04:21.499102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_num = len(y)\n",
    "random_index = np.random.permutation(data_num)\n",
    "\n",
    "x_shuffle = []\n",
    "y_shuffle = []\n",
    "for i in range(data_num):\n",
    "    x_shuffle.append(images[random_index[i]])\n",
    "    y_shuffle.append(y[random_index[i]])\n",
    "    \n",
    "x = np.array(x_shuffle) \n",
    "y = np.array(y_shuffle)\n",
    "val_split_num = int(round(0.2*len(y)))\n",
    "x_train = x[val_split_num:]\n",
    "y_train = y[val_split_num:]\n",
    "x_test = x[:val_split_num]\n",
    "y_test = y[:val_split_num]\n",
    "\n",
    "print('x_train', x_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('x_test', x_test.shape)\n",
    "print('y_test', y_test.shape)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "name_animal = []\n",
    "for i in range(10):\n",
    "    path = train_df[train_df.category == i].values[2]\n",
    "    if path[0].split('/')[-2] == 'scoiattolo':\n",
    "        name_animal.append('squirrel')\n",
    "    elif path[0].split('/')[-2] == 'cavallo':\n",
    "        name_animal.append('horse')\n",
    "    elif path[0].split('/')[-2] == 'farfalla':\n",
    "        name_animal.append('butterfly')\n",
    "    elif path[0].split('/')[-2] == 'mucca':\n",
    "        name_animal.append('cow')\n",
    "    elif path[0].split('/')[-2] == 'gatto':\n",
    "        name_animal.append('cat')\n",
    "    elif path[0].split('/')[-2] == 'pecora':\n",
    "        name_animal.append('sheep')\n",
    "    elif path[0].split('/')[-2] == 'gallina':\n",
    "        name_animal.append('chicken')\n",
    "    elif path[0].split('/')[-2] == 'elefante':\n",
    "        name_animal.append('elephant')\n",
    "    elif path[0].split('/')[-2] == 'ragno':\n",
    "        name_animal.append('spider')\n",
    "    elif path[0].split('/')[-2] == 'cane':\n",
    "        name_animal.append('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T20:04:24.791868Z",
     "iopub.status.busy": "2024-12-15T20:04:24.791561Z",
     "iopub.status.idle": "2024-12-15T20:04:28.419841Z",
     "shell.execute_reply": "2024-12-15T20:04:28.419129Z",
     "shell.execute_reply.started": "2024-12-15T20:04:24.791812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_rows, img_cols, img_channel))\n",
    "\n",
    "add_model = Sequential()\n",
    "add_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "add_model.add(Dense(256, activation='relu'))\n",
    "add_model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=add_model(base_model.output))\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(learning_rate=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T20:04:28.421193Z",
     "iopub.status.busy": "2024-12-15T20:04:28.420956Z",
     "iopub.status.idle": "2024-12-15T20:36:52.166351Z",
     "shell.execute_reply": "2024-12-15T20:36:52.165426Z",
     "shell.execute_reply.started": "2024-12-15T20:04:28.421148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=30, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=True)\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[ModelCheckpoint('VGG16-transferlearning.keras', monitor='val_acc')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T20:36:52.168276Z",
     "iopub.status.busy": "2024-12-15T20:36:52.168007Z",
     "iopub.status.idle": "2024-12-15T20:36:52.502357Z",
     "shell.execute_reply": "2024-12-15T20:36:52.501668Z",
     "shell.execute_reply.started": "2024-12-15T20:36:52.168223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"CNN: Epochs={0:d}, Train accuracy={1:.5f}, Validation accuracy={2:.5f}\".format(epochs,history.history['accuracy'][epochs-1],history.history['val_accuracy'][epochs-1]))\n",
    "def show_plots(history):\n",
    "    \"\"\" Useful function to view plot of loss values & accuracies across the various epochs \"\"\"\n",
    "    loss_vals = history['loss']\n",
    "    val_loss_vals = history['val_loss']\n",
    "    epochs = range(1, len(history['accuracy'])+1)\n",
    "    \n",
    "    f, ax = plt.subplots(nrows=1,ncols=2,figsize=(16,4))\n",
    "    \n",
    "    # plot losses on ax[0]\n",
    "    ax[0].plot(epochs, loss_vals, color='navy',marker='o', linestyle=' ', label='Training Loss')\n",
    "    ax[0].plot(epochs, val_loss_vals, color='firebrick', marker='*', label='Validation Loss')\n",
    "    ax[0].set_title('Training & Validation Loss')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend(loc='best')\n",
    "    ax[0].grid(True)\n",
    "    \n",
    "    # plot accuracies\n",
    "    acc_vals = history['accuracy']\n",
    "    val_acc_vals = history['val_accuracy']\n",
    "\n",
    "    ax[1].plot(epochs, acc_vals, color='navy', marker='o', ls=' ', label='Training Accuracy')\n",
    "    ax[1].plot(epochs, val_acc_vals, color='firebrick', marker='*', label='Validation Accuracy')\n",
    "    ax[1].set_title('Training & Validation Accuracy')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].legend(loc='best')\n",
    "    ax[1].grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # delete locals from heap before exiting\n",
    "    del loss_vals, val_loss_vals, epochs, acc_vals, val_acc_vals\n",
    "show_plots(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T20:36:52.504345Z",
     "iopub.status.busy": "2024-12-15T20:36:52.503881Z",
     "iopub.status.idle": "2024-12-15T20:36:54.634302Z",
     "shell.execute_reply": "2024-12-15T20:36:54.633667Z",
     "shell.execute_reply.started": "2024-12-15T20:36:52.504116Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_images = []\n",
    "j = 39 # change this to get different images\n",
    "for i in range(10):\n",
    "    path = train_df[train_df.category == i].values[j]\n",
    "    a = images[train_df[train_df.filename == path[0]].index[0]]\n",
    "    img = np.array(a)\n",
    "    img = img[:, :, ::-1].copy() \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    if(img.shape[0] > img.shape[1]):\n",
    "        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "    else:\n",
    "        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "    img = centering_image(cv2.resize(img, dsize=tile_size))\n",
    "    img = img[16:240, 16:240]\n",
    "    test_images.append(img)\n",
    "\n",
    "test_images = np.array(test_images).reshape(-1,224,224,3)\n",
    "something = model.predict(test_images)\n",
    "animals = name_animal\n",
    "i = 0\n",
    "for pred in something:\n",
    "    path = train_df[train_df.category == i].values[2]\n",
    "    plt.imshow(test_images[i])\n",
    "    plt.show()\n",
    "    print('Actual  :', animals[i])\n",
    "    print('Predict :', animals[np.where(pred.max() == pred)[0][0]])\n",
    "    i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 59760,
     "sourceId": 840806,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29841,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
