import numpy as np
import cv2
import keras
import streamlit as st
from PIL import Image

CATEGORIES = ['M√®o', 'Ch√≥', 'G√†']

model = keras.models.load_model('model_trained.h5')

audio_files = {
    'M√®o': 'cat.mp3',
    'Ch√≥': 'dog.mp3',
    'G√†': 'chicken.mp3'
}

# Function to process image
def image_to_array(image):
    img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.resize(img, (60, 60))
    img = np.array(img)
    img = img.reshape(-1, 60, 60, 1)
    return img

st.title("Ph√¢n lo·∫°i ƒë·ªông v·∫≠t")

st.write("Upload an image to classify it into cat, dog, or chicken.")

# File uploade
uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "png", "jpeg"])
col1, col2 = st.columns([1, 1])
if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='Uploaded Image', use_column_width=True)

    img_array = image_to_array(image)
    
    prediction = model.predict([img_array])
    predicted_label = CATEGORIES[prediction.argmax()]


    with col2:
        st.subheader("M√¥ t·∫£ chi ti·∫øt")
        if predicted_label == 'M√®o':
            st.write("**M√®o**: Con m√®o l√† m·ªôt lo√†i ƒë·ªông v·∫≠t nh·ªè, l√¥ng m·ªÅm v√† th∆∞·ªùng ƒë∆∞·ª£c nu√¥i l√†m th√∫ c∆∞ng. M√®o c√≥ ƒë√¥i m·∫Øt s·∫Øc b√©n v√† tai nh·ªçn. Ch√∫ng th√≠ch s·ªëng ƒë·ªôc l·∫≠p nh∆∞ng c≈©ng r·∫•t t√¨nh c·∫£m v·ªõi ch·ªß. M√®o th√≠ch c·ªç v√†o ng∆∞·ªùi, k√™u meo meo v√† th√≠ch ng·ªß nhi·ªÅu. Ch√∫ng c≈©ng r·∫•t gi·ªèi b·∫Øt chu·ªôt v√† ch∆°i v·ªùn ƒë·ªì v·∫≠t.")
        elif predicted_label == 'Ch√≥':
            st.write("**Ch√≥**: Con ch√≥ l√† m·ªôt lo√†i ƒë·ªông v·∫≠t nu√¥i r·∫•t ph·ªï bi·∫øn, th∆∞·ªùng ƒë∆∞·ª£c g·ªçi l√† b·∫°n trung th√†nh c·ªßa con ng∆∞·ªùi. Ch√≥ c√≥ k√≠ch th∆∞·ªõc v√† h√¨nh d√°ng ƒëa d·∫°ng, t·ª´ nh·ªè nh∆∞ chihuahua ƒë·∫øn l·ªõn nh∆∞ doberman. Ch√∫ng c√≥ b·ªô l√¥ng ng·∫Øn ho·∫∑c d√†i, v√† ƒë√¥i tai c√≥ th·ªÉ ƒë·ª©ng ho·∫∑c c·ª•p t√πy gi·ªëng.")
        elif predicted_label == 'G√†':
            st.write("**G√†**: Con g√† l√† m·ªôt lo√†i gia c·∫ßm, th∆∞·ªùng ƒë∆∞·ª£c nu√¥i ƒë·ªÉ l·∫•y th·ªãt v√† tr·ª©ng. G√† c√≥ k√≠ch th∆∞·ªõc v·ª´a ph·∫£i, v·ªõi b·ªô l√¥ng m∆∞·ª£t v√† ƒëa d·∫°ng m√†u s·∫Øc. G√† tr·ªëng th∆∞·ªùng c√≥ b·ªô l√¥ng s·∫∑c s·ª° v√† chi·∫øc m√†o ƒë·ªè tr√™n ƒë·∫ßu, trong khi g√† m√°i c√≥ m√†u s·∫Øc nh·∫π nh√†ng h∆°n.")

    # t√™n
    with col1:
        st.write(f"ƒê√¢y l√† con: **{predicted_label}**")
        # √¢m thanh
        if st.button("üîä Play Sound"):
            # Play the audio file corresponding to the predicted animal
            audio_file = f"sound/{audio_files[predicted_label]}"
            audio_bytes = open(audio_file, 'rb').read()
            st.audio(audio_bytes, format='audio/mp3')

    # Optionally, display the image with a rectangle and label (using OpenCV)
    img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    img = cv2.resize(img, (300, 300))
    cv2.rectangle(img, (0, 0), (300, 40), (0, 0, 255), -1)
    cv2.putText(img, f"Prediction: {predicted_label}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
    
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    st.image
